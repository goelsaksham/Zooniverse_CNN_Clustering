{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEC Agglomerative Clustering\n",
    "\n",
    "This notebook focuses on using Agglomerative Clustering instead of other types of clustering algorithms. The notebook will be extended to other algorithms like: Spectral Clustering, DBSCAN, refer to the webpage: https://scikit-learn.org/stable/modules/clustering.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing required Libaries\n",
    "\n",
    "Importing the required libraries and modules so that they can be used in the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# loading the requirements for the Xception model\n",
    "from keras.applications.xception import Xception\n",
    "from keras.applications.xception import absolute_import, decode_predictions, preprocess_input\n",
    "from keras.layers import Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "# Loading the DEC module cloned from github\n",
    "from DEC.model import *\n",
    "from DEC.metrics import *\n",
    "from xception_dec_datagenerator import XceptionDataGenerator\n",
    "# Importing the utilities\n",
    "from utils.file_utils import *\n",
    "from PIL import Image\n",
    "# Using scikit-image  resize function for resizing the image from original size to 224 X 224\n",
    "from skimage.transform import resize\n",
    "# Train Test split from sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from shutil import copy2\n",
    "# For visualization of images and for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xception Model\n",
    "\n",
    "First we load the Xception model into the computer memory using the Keras library. Because we are focusing on extracting features from the model we do not include the topmost layer. However we do use the imagenet weights for the model. Also because we want a 1-D vector form of the features we do use the pooling layer at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor_shape = (150, 150, 3)\n",
    "base_xception_model = Xception(weights = 'imagenet', input_shape = input_tensor_shape, include_top = False, pooling='avg')\n",
    "base_xception_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input shape of our base xception model is: 150 X 150 X 3. That is a 3 channel square image with side 150 pixels.\n",
    "The output shape of the base xception model is: 2048 X 1. It is a 1-D vector representing the features learned by the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Generators\n",
    "\n",
    "Defining the keras data generators to iterate through all the images and then essentially help in extracting the features from the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_extension = '.jpg'\n",
    "training_directory_path = f'../data/xception_clustering/training/'\n",
    "testing_directory_path = f'../data/xception_clustering/testing/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the files already in the training and testing folders respectively\n",
    "spiral_training_directory_path = construct_path(training_directory_path, 'spiral')\n",
    "elliptical_training_directory_path = construct_path(training_directory_path, 'elliptical')\n",
    "spiral_testing_directory_path = construct_path(testing_directory_path, 'spiral')\n",
    "elliptical_testing_directory_path = construct_path(testing_directory_path, 'elliptical')\n",
    "elliptical_training_files = get_file_nms(elliptical_training_directory_path, image_extension)\n",
    "spiral_training_files = get_file_nms(spiral_training_directory_path, image_extension)\n",
    "elliptical_testing_files = get_file_nms(elliptical_testing_directory_path, image_extension)\n",
    "spiral_testing_files = get_file_nms(spiral_testing_directory_path, image_extension)\n",
    "# Finding the number of images for each type of galaxy after finding the common images and list\n",
    "print(f'Number of already present Training Elliptical Galaxies: {len(elliptical_training_files)}')\n",
    "print(f'Number of already present Training Spiral Galaxies: {len(spiral_training_files)}')\n",
    "print(f'Number of already present Testing Elliptical Galaxies: {len(elliptical_testing_files)}')\n",
    "print(f'Number of already present Testing Spiral Galaxies: {len(spiral_testing_files)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalization and Cropping functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_difference(orig_size, target_size):\n",
    "    orig_size, target_size = list(orig_size), list(target_size)\n",
    "    ret_ls = []\n",
    "    for o, t in zip(orig_size, target_size):\n",
    "        ret_ls.append(o - t)\n",
    "    return ret_ls\n",
    "\n",
    "def crop_image(image, orig_size, target_size):\n",
    "    crop_sizes = get_difference(orig_size, target_size)\n",
    "    height_dif, width_dif = crop_sizes[0] // 2, crop_sizes[1] // 2\n",
    "    return image[height_dif:(height_dif + target_size[0]), width_dif:(width_dif + target_size[1]), :]\n",
    "\n",
    "def range_scaling(image, out_feature_range=(-1, 1)):\n",
    "    old_min, old_max = 0., 255.\n",
    "    new_min, new_max = -1., 1.\n",
    "    return ((image - old_min)/(old_max - old_min))*(new_max - new_min) + new_min\n",
    "\n",
    "def image_preprocessing_function(image, crop=True, range_scale=True):\n",
    "    \"\"\"\n",
    "    image is a 3-D image tensor (numpy array).\n",
    "    \"\"\"\n",
    "    target_image_size = input_tensor_shape\n",
    "    if crop:\n",
    "        cropped_image = crop_image(image, image.shape, target_image_size)\n",
    "    else:\n",
    "        cropped_image = image\n",
    "        \n",
    "    if range_scale:\n",
    "        final_image = range_scaling(cropped_image)\n",
    "    else:\n",
    "        final_image = cropped_image\n",
    "    return final_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generator Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "generator_batch_size = 64\n",
    "# Current generator uses -1 to 1\n",
    "image_generator = ImageDataGenerator(preprocessing_function=image_preprocessing_function)\n",
    "training_generator = image_generator.flow_from_directory(training_directory_path, target_size = input_tensor_shape[:2], \n",
    "                                                         class_mode='binary', batch_size=generator_batch_size)\n",
    "testing_generator = image_generator.flow_from_directory(testing_directory_path, target_size = input_tensor_shape[:2], \n",
    "                                                         class_mode='binary', batch_size=generator_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "n_train_examples = (len(training_generator.filenames)//generator_batch_size) * generator_batch_size\n",
    "train_features = np.zeros((n_train_examples, 2048))\n",
    "train_labels = np.zeros(n_train_examples, dtype=int)\n",
    "i = 0\n",
    "for inputs_batch, labels_batch in training_generator:\n",
    "    features_batch = base_xception_model.predict(inputs_batch)\n",
    "    train_features[i * generator_batch_size : (i + 1) * generator_batch_size] = features_batch\n",
    "    train_labels[i * generator_batch_size : (i + 1) * generator_batch_size] = labels_batch\n",
    "    i += 1\n",
    "    if i % 100 == 0 and i:\n",
    "        print('Number of Images processed:', i * generator_batch_size)\n",
    "    if i * generator_batch_size >= n_train_examples:\n",
    "        break\n",
    "\n",
    "print('Shape of the training features', train_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_generator.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single-Link Agglomerative Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEC Xception Training Regime\n",
    "\n",
    "This part of the notebook defines the generator for the training regime of the DEC model over the features extracted from the Xception architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining our DEC model\n",
    "dec_model = DEC_Agglomerative([2048, 500, 500, 2000, 10], n_clusters=2)\n",
    "dec_model.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_save_dir = 'results/single_link_agglomerative_clustering'\n",
    "if not exist_directory(results_save_dir):\n",
    "    os.makedirs(results_save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pretraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "dec_model.pretrain(train_features, train_labels, epochs=100, save_dir=results_save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dec_model.compile(optimizer=SGD(0.01, 0.9), loss='kld')\n",
    "y_pred = dec_model.fit(train_features, y=train_labels, batch_size=32, save_dir=results_save_dir, \n",
    "                       cluster_linkage='single')\n",
    "print('acc:', metrics.acc(train_labels, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of the features extracted by the DEC model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoder Output Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dec_encoder_model_pred = dec_model.encoder.predict(train_features)\n",
    "pca_mod = PCA(2)\n",
    "pca_mod.fit(dec_encoder_model_pred)\n",
    "reduced_features = pca_mod.transform(dec_encoder_model_pred)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "sns.scatterplot(reduced_features[:, 0], reduced_features[:, 1], \n",
    "                hue=np.where(train_labels==0, 'elliptical', 'spiral'), ax=ax)\n",
    "ax.text(0.02, 0.92, f'Explained Var: {np.round(np.sum(pca_mod.explained_variance_ratio_), decimals=4)}', \n",
    "        transform=ax.transAxes)\n",
    "ax.set_xlabel('PCA Dim 1')\n",
    "ax.set_ylabel('PCA Dim 2')\n",
    "ax.set_title('PCA Scatterplot for Encoder Features')\n",
    "plt.savefig(f'{results_save_dir}/PCAencoding_pca_features.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete-Link Agglomerative Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEC Xception Training Regime\n",
    "\n",
    "This part of the notebook defines the generator for the training regime of the DEC model over the features extracted from the Xception architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining our DEC model\n",
    "dec_model = DEC_Agglomerative([2048, 500, 500, 2000, 10], n_clusters=2)\n",
    "dec_model.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_save_dir = 'results/complete_link_agglomerative_clustering'\n",
    "if not exist_directory(results_save_dir):\n",
    "    os.makedirs(results_save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pretraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "dec_model.pretrain(train_features, train_labels, epochs=100, save_dir=results_save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dec_model.compile(optimizer=SGD(0.01, 0.9), loss='kld')\n",
    "y_pred = dec_model.fit(train_features, y=train_labels, batch_size=32, save_dir=results_save_dir, \n",
    "                       cluster_linkage='complete')\n",
    "print('acc:', metrics.acc(train_labels, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of the features extracted by the DEC model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoder Output Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dec_encoder_model_pred = dec_model.encoder.predict(train_features)\n",
    "pca_mod = PCA(2)\n",
    "pca_mod.fit(dec_encoder_model_pred)\n",
    "reduced_features = pca_mod.transform(dec_encoder_model_pred)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "sns.scatterplot(reduced_features[:, 0], reduced_features[:, 1], \n",
    "                hue=np.where(train_labels==0, 'elliptical', 'spiral'), ax=ax)\n",
    "ax.text(0.02, 0.92, f'Explained Var: {np.round(np.sum(pca_mod.explained_variance_ratio_), decimals=4)}', \n",
    "        transform=ax.transAxes)\n",
    "ax.set_xlabel('PCA Dim 1')\n",
    "ax.set_ylabel('PCA Dim 2')\n",
    "ax.set_title('PCA Scatterplot for Encoder Features')\n",
    "plt.savefig(f'{results_save_dir}/PCAencoding_pca_features.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average-Link Agglomerative Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEC Xception Training Regime\n",
    "\n",
    "This part of the notebook defines the generator for the training regime of the DEC model over the features extracted from the Xception architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining our DEC model\n",
    "dec_model = DEC_Agglomerative([2048, 500, 500, 2000, 10], n_clusters=2)\n",
    "dec_model.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_save_dir = 'results/average_link_agglomerative_clustering'\n",
    "if not exist_directory(results_save_dir):\n",
    "    os.makedirs(results_save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pretraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "dec_model.pretrain(train_features, train_labels, epochs=100, save_dir=results_save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dec_model.compile(optimizer=SGD(0.01, 0.9), loss='kld')\n",
    "y_pred = dec_model.fit(train_features, y=train_labels, batch_size=32, save_dir=results_save_dir, \n",
    "                       cluster_linkage='average')\n",
    "print('acc:', metrics.acc(train_labels, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of the features extracted by the DEC model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoder Output Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dec_encoder_model_pred = dec_model.encoder.predict(train_features)\n",
    "pca_mod = PCA(2)\n",
    "pca_mod.fit(dec_encoder_model_pred)\n",
    "reduced_features = pca_mod.transform(dec_encoder_model_pred)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "sns.scatterplot(reduced_features[:, 0], reduced_features[:, 1], \n",
    "                hue=np.where(train_labels==0, 'elliptical', 'spiral'), ax=ax)\n",
    "ax.text(0.02, 0.92, f'Explained Var: {np.round(np.sum(pca_mod.explained_variance_ratio_), decimals=4)}', \n",
    "        transform=ax.transAxes)\n",
    "ax.set_xlabel('PCA Dim 1')\n",
    "ax.set_ylabel('PCA Dim 2')\n",
    "ax.set_title('PCA Scatterplot for Encoder Features')\n",
    "plt.savefig(f'{results_save_dir}/PCAencoding_pca_features.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ward-Link Agglomerative Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEC Xception Training Regime\n",
    "\n",
    "This part of the notebook defines the generator for the training regime of the DEC model over the features extracted from the Xception architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining our DEC model\n",
    "dec_model = DEC_Agglomerative([2048, 500, 500, 2000, 10], n_clusters=2)\n",
    "dec_model.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_save_dir = 'results/ward_link_agglomerative_clustering'\n",
    "if not exist_directory(results_save_dir):\n",
    "    os.makedirs(results_save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pretraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "dec_model.pretrain(train_features, train_labels, epochs=100, save_dir=results_save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dec_model.compile(optimizer=SGD(0.01, 0.9), loss='kld')\n",
    "y_pred = dec_model.fit(train_features, y=train_labels, batch_size=32, save_dir=results_save_dir, \n",
    "                       cluster_linkage='complete')\n",
    "print('acc:', metrics.acc(train_labels, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of the features extracted by the DEC model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoder Output Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dec_encoder_model_pred = dec_model.encoder.predict(train_features)\n",
    "pca_mod = PCA(2)\n",
    "pca_mod.fit(dec_encoder_model_pred)\n",
    "reduced_features = pca_mod.transform(dec_encoder_model_pred)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "sns.scatterplot(reduced_features[:, 0], reduced_features[:, 1], \n",
    "                hue=np.where(train_labels==0, 'elliptical', 'spiral'), ax=ax)\n",
    "ax.text(0.02, 0.92, f'Explained Var: {np.round(np.sum(pca_mod.explained_variance_ratio_), decimals=4)}', \n",
    "        transform=ax.transAxes)\n",
    "ax.set_xlabel('PCA Dim 1')\n",
    "ax.set_ylabel('PCA Dim 2')\n",
    "ax.set_title('PCA Scatterplot for Encoder Features')\n",
    "plt.savefig(f'{results_save_dir}/PCAencoding_pca_features.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
