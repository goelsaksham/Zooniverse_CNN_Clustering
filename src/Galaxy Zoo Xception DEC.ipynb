{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XCEPTION + DEC Model on Galaxy Zoo Dataset\n",
    "\n",
    "This notebook loads the xception model and tries to extract features from the Xception Model for all the galaxy zoo images. Then it invokes a DEC model on top of the features extracted to perform the required clustering. This notebook acts as a step by step guide through the whole process and also as a way of performing the experiment for the current research of clustering galaxies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing required Libaries\n",
    "\n",
    "Importing the required libraries and modules so that they can be used in the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# loading the requirements for the Xception model\n",
    "from keras.applications.xception import Xception\n",
    "from keras.applications.xception import absolute_import, decode_predictions, preprocess_input\n",
    "from keras.layers import Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "# Loading the DEC module cloned from github\n",
    "from DEC.model import *\n",
    "from DEC.metrics import *\n",
    "from xception_dec_datagenerator import XceptionDataGenerator\n",
    "# Importing the utilities\n",
    "from utils.file_utils import *\n",
    "from PIL import Image\n",
    "# Using scikit-image  resize function for resizing the image from original size to 224 X 224\n",
    "from skimage.transform import resize\n",
    "# Train Test split from sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from shutil import copy2\n",
    "# For visualization of images and for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xception Model\n",
    "\n",
    "First we load the Xception model into the computer memory using the Keras library. Because we are focusing on extracting features from the model we do not include the topmost layer. However we do use the imagenet weights for the model. Also because we want a 1-D vector form of the features we do use the pooling layer at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 111, 111, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_bn (BatchNormaliza (None, 111, 111, 32) 128         block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_act (Activation)   (None, 111, 111, 32) 0           block1_conv1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 109, 109, 64) 18432       block1_conv1_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_bn (BatchNormaliza (None, 109, 109, 64) 256         block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_act (Activation)   (None, 109, 109, 64) 0           block1_conv2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1 (SeparableConv2 (None, 109, 109, 128 8768        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1_bn (BatchNormal (None, 109, 109, 128 512         block2_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_act (Activation (None, 109, 109, 128 0           block2_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2 (SeparableConv2 (None, 109, 109, 128 17536       block2_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_bn (BatchNormal (None, 109, 109, 128 512         block2_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 55, 55, 128)  8192        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 55, 55, 128)  0           block2_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 55, 55, 128)  512         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 55, 55, 128)  0           block2_pool[0][0]                \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_act (Activation (None, 55, 55, 128)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1 (SeparableConv2 (None, 55, 55, 256)  33920       block3_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_bn (BatchNormal (None, 55, 55, 256)  1024        block3_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_act (Activation (None, 55, 55, 256)  0           block3_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2 (SeparableConv2 (None, 55, 55, 256)  67840       block3_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_bn (BatchNormal (None, 55, 55, 256)  1024        block3_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 28, 28, 256)  32768       add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 28, 28, 256)  0           block3_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 28, 28, 256)  1024        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 28, 28, 256)  0           block3_pool[0][0]                \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_act (Activation (None, 28, 28, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1 (SeparableConv2 (None, 28, 28, 728)  188672      block4_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_bn (BatchNormal (None, 28, 28, 728)  2912        block4_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_act (Activation (None, 28, 28, 728)  0           block4_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2 (SeparableConv2 (None, 28, 28, 728)  536536      block4_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_bn (BatchNormal (None, 28, 28, 728)  2912        block4_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 14, 14, 728)  186368      add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 14, 14, 728)  0           block4_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 14, 14, 728)  2912        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 14, 14, 728)  0           block4_pool[0][0]                \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_act (Activation (None, 14, 14, 728)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1 (SeparableConv2 (None, 14, 14, 728)  536536      block5_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_bn (BatchNormal (None, 14, 14, 728)  2912        block5_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_act (Activation (None, 14, 14, 728)  0           block5_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2 (SeparableConv2 (None, 14, 14, 728)  536536      block5_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_bn (BatchNormal (None, 14, 14, 728)  2912        block5_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_act (Activation (None, 14, 14, 728)  0           block5_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3 (SeparableConv2 (None, 14, 14, 728)  536536      block5_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_bn (BatchNormal (None, 14, 14, 728)  2912        block5_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 14, 14, 728)  0           block5_sepconv3_bn[0][0]         \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_act (Activation (None, 14, 14, 728)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1 (SeparableConv2 (None, 14, 14, 728)  536536      block6_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_bn (BatchNormal (None, 14, 14, 728)  2912        block6_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_act (Activation (None, 14, 14, 728)  0           block6_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2 (SeparableConv2 (None, 14, 14, 728)  536536      block6_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_bn (BatchNormal (None, 14, 14, 728)  2912        block6_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_act (Activation (None, 14, 14, 728)  0           block6_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3 (SeparableConv2 (None, 14, 14, 728)  536536      block6_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_bn (BatchNormal (None, 14, 14, 728)  2912        block6_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 14, 14, 728)  0           block6_sepconv3_bn[0][0]         \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_act (Activation (None, 14, 14, 728)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1 (SeparableConv2 (None, 14, 14, 728)  536536      block7_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_bn (BatchNormal (None, 14, 14, 728)  2912        block7_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_act (Activation (None, 14, 14, 728)  0           block7_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2 (SeparableConv2 (None, 14, 14, 728)  536536      block7_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_bn (BatchNormal (None, 14, 14, 728)  2912        block7_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_act (Activation (None, 14, 14, 728)  0           block7_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3 (SeparableConv2 (None, 14, 14, 728)  536536      block7_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_bn (BatchNormal (None, 14, 14, 728)  2912        block7_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 14, 14, 728)  0           block7_sepconv3_bn[0][0]         \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_act (Activation (None, 14, 14, 728)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1 (SeparableConv2 (None, 14, 14, 728)  536536      block8_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_bn (BatchNormal (None, 14, 14, 728)  2912        block8_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_act (Activation (None, 14, 14, 728)  0           block8_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2 (SeparableConv2 (None, 14, 14, 728)  536536      block8_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_bn (BatchNormal (None, 14, 14, 728)  2912        block8_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_act (Activation (None, 14, 14, 728)  0           block8_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3 (SeparableConv2 (None, 14, 14, 728)  536536      block8_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_bn (BatchNormal (None, 14, 14, 728)  2912        block8_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 14, 14, 728)  0           block8_sepconv3_bn[0][0]         \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_act (Activation (None, 14, 14, 728)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1 (SeparableConv2 (None, 14, 14, 728)  536536      block9_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_bn (BatchNormal (None, 14, 14, 728)  2912        block9_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_act (Activation (None, 14, 14, 728)  0           block9_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2 (SeparableConv2 (None, 14, 14, 728)  536536      block9_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_bn (BatchNormal (None, 14, 14, 728)  2912        block9_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_act (Activation (None, 14, 14, 728)  0           block9_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3 (SeparableConv2 (None, 14, 14, 728)  536536      block9_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_bn (BatchNormal (None, 14, 14, 728)  2912        block9_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 14, 14, 728)  0           block9_sepconv3_bn[0][0]         \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_act (Activatio (None, 14, 14, 728)  0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1 (SeparableConv (None, 14, 14, 728)  536536      block10_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_bn (BatchNorma (None, 14, 14, 728)  2912        block10_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_act (Activatio (None, 14, 14, 728)  0           block10_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2 (SeparableConv (None, 14, 14, 728)  536536      block10_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_bn (BatchNorma (None, 14, 14, 728)  2912        block10_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_act (Activatio (None, 14, 14, 728)  0           block10_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3 (SeparableConv (None, 14, 14, 728)  536536      block10_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_bn (BatchNorma (None, 14, 14, 728)  2912        block10_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 14, 14, 728)  0           block10_sepconv3_bn[0][0]        \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_act (Activatio (None, 14, 14, 728)  0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1 (SeparableConv (None, 14, 14, 728)  536536      block11_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_bn (BatchNorma (None, 14, 14, 728)  2912        block11_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_act (Activatio (None, 14, 14, 728)  0           block11_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2 (SeparableConv (None, 14, 14, 728)  536536      block11_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_bn (BatchNorma (None, 14, 14, 728)  2912        block11_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_act (Activatio (None, 14, 14, 728)  0           block11_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3 (SeparableConv (None, 14, 14, 728)  536536      block11_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_bn (BatchNorma (None, 14, 14, 728)  2912        block11_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 14, 14, 728)  0           block11_sepconv3_bn[0][0]        \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_act (Activatio (None, 14, 14, 728)  0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1 (SeparableConv (None, 14, 14, 728)  536536      block12_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_bn (BatchNorma (None, 14, 14, 728)  2912        block12_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_act (Activatio (None, 14, 14, 728)  0           block12_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2 (SeparableConv (None, 14, 14, 728)  536536      block12_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_bn (BatchNorma (None, 14, 14, 728)  2912        block12_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_act (Activatio (None, 14, 14, 728)  0           block12_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3 (SeparableConv (None, 14, 14, 728)  536536      block12_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_bn (BatchNorma (None, 14, 14, 728)  2912        block12_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 14, 14, 728)  0           block12_sepconv3_bn[0][0]        \n",
      "                                                                 add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_act (Activatio (None, 14, 14, 728)  0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1 (SeparableConv (None, 14, 14, 728)  536536      block13_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_bn (BatchNorma (None, 14, 14, 728)  2912        block13_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_act (Activatio (None, 14, 14, 728)  0           block13_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2 (SeparableConv (None, 14, 14, 1024) 752024      block13_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_bn (BatchNorma (None, 14, 14, 1024) 4096        block13_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 7, 7, 1024)   745472      add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_pool (MaxPooling2D)     (None, 7, 7, 1024)   0           block13_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 7, 7, 1024)   4096        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 7, 7, 1024)   0           block13_pool[0][0]               \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1 (SeparableConv (None, 7, 7, 1536)   1582080     add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_bn (BatchNorma (None, 7, 7, 1536)   6144        block14_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_act (Activatio (None, 7, 7, 1536)   0           block14_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2 (SeparableConv (None, 7, 7, 2048)   3159552     block14_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_bn (BatchNorma (None, 7, 7, 2048)   8192        block14_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_act (Activatio (None, 7, 7, 2048)   0           block14_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 2048)         0           block14_sepconv2_act[0][0]       \n",
      "==================================================================================================\n",
      "Total params: 20,861,480\n",
      "Trainable params: 20,806,952\n",
      "Non-trainable params: 54,528\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_tensor_shape = (224, 224, 3)\n",
    "base_xception_model = Xception(weights = 'imagenet', input_shape = input_tensor_shape, include_top = False, pooling='avg')\n",
    "base_xception_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input shape of our base xception model is: 224 X 224 X 3. That is a 3 channel square image with side 224 pixels.\n",
    "The output shape of the base xception model is: 2048 X 1. It is a 1-D vector representing the features learned by the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Galaxy Zoo data\n",
    "\n",
    "We now start loading the galaxy zoo data into memory. First we load the label file and then start loading the corresponding images such that we can assign the corresponding label to them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'../data/galaxy_zoo/training_solutions_rev1.csv' does not exist: b'../data/galaxy_zoo/training_solutions_rev1.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-b585d093b8cb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mall_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'../data/galaxy_zoo/training_solutions_rev1.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mall_labels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    701\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    703\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 429\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1120\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1121\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1122\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1123\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1124\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'usecols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1852\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1855\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File b'../data/galaxy_zoo/training_solutions_rev1.csv' does not exist: b'../data/galaxy_zoo/training_solutions_rev1.csv'"
     ]
    }
   ],
   "source": [
    "all_labels = pd.read_csv(f'../data/galaxy_zoo/training_solutions_rev1.csv')\n",
    "all_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming the follwing column names:\n",
    "elliptical_galaxy_col_name = 'Class1.1'\n",
    "spiral_galaxy_col_name = 'Class1.2'\n",
    "\n",
    "# elliptical_galaxy_ids = pd.Series(all_labels[all_labels[elliptical_galaxy_col_name] > all_labels[spiral_galaxy_col_name]]['GalaxyID'], dtype=str)\n",
    "elliptical_galaxy_ids = pd.Series(all_labels[all_labels[elliptical_galaxy_col_name] >= 0.5]['GalaxyID'], dtype=str)\n",
    "# spiral_galaxy_ids = pd.Series(all_labels[all_labels[spiral_galaxy_col_name] > all_labels[elliptical_galaxy_col_name]]['GalaxyID'], dtype=str)\n",
    "spiral_galaxy_ids = pd.Series(all_labels[all_labels[spiral_galaxy_col_name] > 0.5]['GalaxyID'], dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the number of images for each type of galaxy\n",
    "print(f'Number Elliptical Galaxies: {elliptical_galaxy_ids.shape[0]}')\n",
    "print(f'Number Spiral Galaxies: {spiral_galaxy_ids.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elliptical Galaxy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elliptical_galaxy_ids.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not using cv2 because it reads the image channels in a reverse order (BGR instead of RGB)\n",
    "# elliptical_image = cv2.imread(f'../data/galaxy_zoo/galaxy-zoo-the-galaxy-challenge/images_training_rev1/images_training_rev1/100053.jpg')\n",
    "elliptical_image = Image.open(f'../data/galaxy_zoo/images_training_rev1/100053.jpg')\n",
    "plt.imshow(elliptical_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First finding the input shape of the image\n",
    "print(f'Original Image Size: {np.array(elliptical_image).shape}')\n",
    "ellip_image_arr = resize(np.array(elliptical_image), input_tensor_shape)\n",
    "print(f'Resized Image Size: {ellip_image_arr.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ellip_predications = base_xception_model.predict(ellip_image_arr.reshape((-1,) + input_tensor_shape))\n",
    "print(ellip_predications)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spiral Galaxy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spiral_galaxy_ids.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not using cv2 because it reads the image channels in a reverse order (BGR instead of RGB)\n",
    "# spiral_image = cv2.imread(f'../data/galaxy_zoo/galaxy-zoo-the-galaxy-challenge/images_training_rev1/images_training_rev1/100008.jpg')\n",
    "spiral_image = Image.open(f'../data/galaxy_zoo/images_training_rev1/100008.jpg')\n",
    "plt.imshow(spiral_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First finding the input shape of the image\n",
    "print(f'Original Image Size: {np.array(spiral_image).shape}')\n",
    "spiral_image_arr = resize(np.array(spiral_image), input_tensor_shape)\n",
    "print(f'Resized Image Size: {spiral_image_arr.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "spiral_predications = base_xception_model.predict(spiral_image_arr.reshape((-1,) + input_tensor_shape))\n",
    "print(spiral_predications)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Validation\n",
    "\n",
    "Validate whether all the images are in the required place of the training and the testing directories. Make sure we copy all the required images from the galaxy zoo data lake to the correct place and then define all the generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True True\n"
     ]
    }
   ],
   "source": [
    "data_lake_path = f'../data/galaxy_zoo/images_training_rev1/'\n",
    "print(exist_directory(data_lake_path))\n",
    "training_directory_path = f'../data/xception_clustering/training/'\n",
    "testing_directory_path = f'../data/xception_clustering/testing/'\n",
    "print(exist_directory(training_directory_path), exist_directory(testing_directory_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'spiral_galaxy_ids' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-7f94b0289441>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mall_image_files\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_file_nms\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_lake_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_extension\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_image_files\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mcommon_spiral_galaxy_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspiral_galaxy_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintersection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_image_files\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mcommon_elliptical_galaxy_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melliptical_galaxy_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintersection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_image_files\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# Finding the number of images for each type of galaxy after finding the common images and list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'spiral_galaxy_ids' is not defined"
     ]
    }
   ],
   "source": [
    "# Get file names for the different types of galaxies from the dataframe that are also present in the dataset\n",
    "image_extension = '.jpg'\n",
    "all_image_files = get_file_nms(data_lake_path, image_extension)\n",
    "print(len(all_image_files))\n",
    "common_spiral_galaxy_ids = list(set(spiral_galaxy_ids).intersection(all_image_files))\n",
    "common_elliptical_galaxy_ids = list(set(elliptical_galaxy_ids).intersection(all_image_files))\n",
    "# Finding the number of images for each type of galaxy after finding the common images and list\n",
    "print(f'Number of common Elliptical Galaxies: {len(common_elliptical_galaxy_ids)}')\n",
    "print(f'Number of common Spiral Galaxies: {len(common_spiral_galaxy_ids)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of already present Training Elliptical Galaxies: 0\n",
      "Number of already present Training Spiral Galaxies: 0\n",
      "Number of already present Training Elliptical Galaxies: 0\n",
      "Number of already present Training Spiral Galaxies: 0\n"
     ]
    }
   ],
   "source": [
    "# Getting the files already in the training and testing folders respectively\n",
    "spiral_training_directory_path = construct_path(training_directory_path, 'spiral')\n",
    "elliptical_training_directory_path = construct_path(training_directory_path, 'elliptical')\n",
    "spiral_testing_directory_path = construct_path(testing_directory_path, 'spiral')\n",
    "elliptical_testing_directory_path = construct_path(testing_directory_path, 'elliptical')\n",
    "elliptical_training_files = get_file_nms(elliptical_training_directory_path, image_extension)\n",
    "spiral_training_files = get_file_nms(spiral_training_directory_path, image_extension)\n",
    "elliptical_testing_files = get_file_nms(elliptical_testing_directory_path, image_extension)\n",
    "spiral_testing_files = get_file_nms(spiral_testing_directory_path, image_extension)\n",
    "# Finding the number of images for each type of galaxy after finding the common images and list\n",
    "print(f'Number of already present Training Elliptical Galaxies: {len(elliptical_training_files)}')\n",
    "print(f'Number of already present Training Spiral Galaxies: {len(spiral_training_files)}')\n",
    "print(f'Number of already present Training Elliptical Galaxies: {len(elliptical_testing_files)}')\n",
    "print(f'Number of already present Training Spiral Galaxies: {len(spiral_testing_files)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into training and testing split\n",
    "train_galaxy_ids_elliptical, test_galaxy_ids_elliptical = train_test_split(common_elliptical_galaxy_ids, test_size=0.)\n",
    "train_galaxy_ids_spiral, test_galaxy_ids_spiral = train_test_split(common_spiral_galaxy_ids, test_size=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25868, 34105)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_galaxy_ids_elliptical), len(train_galaxy_ids_spiral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n",
      "Hello\n",
      "Hello\n",
      "CPU times: user 3 s, sys: 3 s, total: 6 s\n",
      "Wall time: 6.67 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Iterating to copy the data\n",
    "for file_name in set(train_galaxy_ids_elliptical) - elliptical_training_files:\n",
    "    input_file_path = construct_path(data_lake_path, f'{file_name}{image_extension}')\n",
    "    outut_file_path = construct_path(elliptical_training_directory_path, f'{file_name}{image_extension}')\n",
    "    copy2(input_file_path, outut_file_path)\n",
    "\n",
    "for file_name in set(test_galaxy_ids_elliptical) - elliptical_testing_files:\n",
    "    input_file_path = construct_path(data_lake_path, f'{file_name}{image_extension}')\n",
    "    outut_file_path = construct_path(elliptical_testing_directory_path, f'{file_name}{image_extension}')\n",
    "    copy2(input_file_path, outut_file_path)\n",
    "print('Hello')    \n",
    "for file_name in set(train_galaxy_ids_spiral) - spiral_training_files:\n",
    "    input_file_path = construct_path(data_lake_path, f'{file_name}{image_extension}')\n",
    "    outut_file_path = construct_path(spiral_training_directory_path, f'{file_name}{image_extension}')\n",
    "    copy2(input_file_path, outut_file_path)\n",
    "print('Hello')    \n",
    "for file_name in set(test_galaxy_ids_spiral) - spiral_testing_files:\n",
    "    input_file_path = construct_path(data_lake_path, f'{file_name}{image_extension}')\n",
    "    outut_file_path = construct_path(spiral_testing_directory_path, f'{file_name}{image_extension}')\n",
    "    copy2(input_file_path, outut_file_path)\n",
    "print('Hello')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Generators\n",
    "\n",
    "Defining the keras data generators to iterate through all the images and then essentially help in extracting the features from the images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Featurewise Centering Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 59973 images belonging to 2 classes.\n",
      "Found 0 images belonging to 2 classes.\n",
      "CPU times: user 3 s, sys: 820 ms, total: 3.82 s\n",
      "Wall time: 2.75 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "generator_batch_size = 64\n",
    "image_generator = ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True)\n",
    "training_generator = image_generator.flow_from_directory(training_directory_path, target_size = input_tensor_shape[:2], \n",
    "                                                         class_mode='binary', batch_size=generator_batch_size)\n",
    "testing_generator = image_generator.flow_from_directory(testing_directory_path, target_size = input_tensor_shape[:2], \n",
    "                                                         class_mode='binary', batch_size=generator_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11min 21s, sys: 3min 40s, total: 15min 1s\n",
      "Wall time: 14min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n_train_examples = (len(training_generator.filenames)//generator_batch_size) * generator_batch_size\n",
    "train_features = np.zeros((n_train_examples, 2048))\n",
    "train_labels = np.zeros(n_train_examples, dtype=int)\n",
    "i = 0\n",
    "for inputs_batch, labels_batch in training_generator:\n",
    "    features_batch = base_xception_model.predict(inputs_batch)\n",
    "    train_features[i * generator_batch_size : (i + 1) * generator_batch_size] = features_batch\n",
    "    train_labels[i * generator_batch_size : (i + 1) * generator_batch_size] = labels_batch\n",
    "    i += 1\n",
    "    if i * generator_batch_size >= n_train_examples:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59968, 2048)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# other type of feature generation\n",
    "#%%time\n",
    "#number_training_samples = len(training_generator.filenames)\n",
    "#number_testing_samples = len(testing_generator.filenames)\n",
    "#train_features = base_xception_model.predict_generator(training_generator, steps=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -1 to 1 Range Data Generation along with Cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_difference(orig_size, target_size):\n",
    "    orig_size, target_size = list(orig_size), list(target_size)\n",
    "    ret_ls = []\n",
    "    for o, t in zip(orig_size, target_size):\n",
    "        ret_ls.append(o - t)\n",
    "    return ret_ls\n",
    "\n",
    "def crop_image(image, orig_size, target_size):\n",
    "    crop_sizes = get_difference(orig_size, target_size)\n",
    "    height_dif, width_dif = crop_sizes[0] // 2, crop_sizes[1] // 2\n",
    "    return image[height_dif:(height_dif + target_size[0]), width_dif:(width_dif + target_size[1]), :]\n",
    "\n",
    "def range_scaling(image):\n",
    "    old_min, old_max = 0., 255.\n",
    "    new_min, new_max = -1., 1.\n",
    "    return ((image - old_min)/(old_max - old_min))*(new_max - new_min) + new_min\n",
    "\n",
    "def image_preprocessing_function(image):\n",
    "    \"\"\"\n",
    "    image is a 3-D image tensor (numpy array).\n",
    "    \"\"\"\n",
    "    target_image_size = input_tensor_shape\n",
    "    cropped_image = crop_image(image, image.shape, target_image_size)\n",
    "    return range_scaling(crop_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 59973 images belonging to 2 classes.\n",
      "Found 0 images belonging to 2 classes.\n",
      "CPU times: user 3 s, sys: 820 ms, total: 3.82 s\n",
      "Wall time: 2.75 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "generator_batch_size = 64\n",
    "image_generator = ImageDataGenerator(preprocessing_function=image_preprocessing_function)\n",
    "training_generator = image_generator.flow_from_directory(training_directory_path, target_size = input_tensor_shape[:2], \n",
    "                                                         class_mode='binary', batch_size=generator_batch_size)\n",
    "testing_generator = image_generator.flow_from_directory(testing_directory_path, target_size = input_tensor_shape[:2], \n",
    "                                                         class_mode='binary', batch_size=generator_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11min 21s, sys: 3min 40s, total: 15min 1s\n",
      "Wall time: 14min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n_train_examples = (len(training_generator.filenames)//generator_batch_size) * generator_batch_size\n",
    "train_features = np.zeros((n_train_examples, 2048))\n",
    "train_labels = np.zeros(n_train_examples, dtype=int)\n",
    "i = 0\n",
    "for inputs_batch, labels_batch in training_generator:\n",
    "    features_batch = base_xception_model.predict(inputs_batch)\n",
    "    train_features[i * generator_batch_size : (i + 1) * generator_batch_size] = features_batch\n",
    "    train_labels[i * generator_batch_size : (i + 1) * generator_batch_size] = labels_batch\n",
    "    i += 1\n",
    "    if i * generator_batch_size >= n_train_examples:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59968, 2048)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# other type of feature generation\n",
    "#%%time\n",
    "#number_training_samples = len(training_generator.filenames)\n",
    "#number_testing_samples = len(testing_generator.filenames)\n",
    "#train_features = base_xception_model.predict_generator(training_generator, steps=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEC Xception Training Regime\n",
    "\n",
    "This part of the notebook defines the generator for the training regime of the DEC model over the features extracted from the Xception architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "encoder_0 (Dense)            (None, 500)               1024500   \n",
      "_________________________________________________________________\n",
      "encoder_1 (Dense)            (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "encoder_2 (Dense)            (None, 2000)              1002000   \n",
      "_________________________________________________________________\n",
      "encoder_3 (Dense)            (None, 10)                20010     \n",
      "_________________________________________________________________\n",
      "clustering (ClusteringLayer) (None, 2)                 20        \n",
      "=================================================================\n",
      "Total params: 2,297,030\n",
      "Trainable params: 2,297,030\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Defining our DEC model\n",
    "dec_model = DEC([2048, 500, 500, 2000, 10], n_clusters=2)\n",
    "dec_model.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Pretraining...\n",
      "Epoch 1/200\n",
      "59968/59968 [==============================] - 5s 85us/step - loss: 1.2983\n",
      "        |==>  acc: 0.5492,  nmi: 0.0047  <==|\n",
      "Epoch 2/200\n",
      "59968/59968 [==============================] - 5s 76us/step - loss: 0.7145\n",
      "Epoch 3/200\n",
      "59968/59968 [==============================] - 4s 68us/step - loss: 0.5992\n",
      "Epoch 4/200\n",
      "59968/59968 [==============================] - 4s 67us/step - loss: 0.6081\n",
      "Epoch 5/200\n",
      "59968/59968 [==============================] - 4s 69us/step - loss: 0.4991\n",
      "Epoch 6/200\n",
      "59968/59968 [==============================] - 4s 67us/step - loss: 0.4963\n",
      "Epoch 7/200\n",
      "59968/59968 [==============================] - 4s 69us/step - loss: 0.5262\n",
      "Epoch 8/200\n",
      "59968/59968 [==============================] - 4s 69us/step - loss: 0.4864\n",
      "Epoch 9/200\n",
      "59968/59968 [==============================] - 4s 70us/step - loss: 0.5063\n",
      "Epoch 10/200\n",
      "59968/59968 [==============================] - 4s 69us/step - loss: 0.4861\n",
      "Epoch 11/200\n",
      "59968/59968 [==============================] - 4s 66us/step - loss: 0.5137\n",
      "Epoch 12/200\n",
      "59968/59968 [==============================] - 4s 67us/step - loss: 0.4905\n",
      "Epoch 13/200\n",
      "59968/59968 [==============================] - 4s 68us/step - loss: 0.4622\n",
      "Epoch 14/200\n",
      "59968/59968 [==============================] - 4s 69us/step - loss: 0.4288\n",
      "Epoch 15/200\n",
      "59968/59968 [==============================] - 4s 70us/step - loss: 0.3916\n",
      "Epoch 16/200\n",
      "59968/59968 [==============================] - 4s 70us/step - loss: 0.4557\n",
      "Epoch 17/200\n",
      "59968/59968 [==============================] - 4s 70us/step - loss: 0.4099\n",
      "Epoch 18/200\n",
      "59968/59968 [==============================] - 4s 69us/step - loss: 0.4418\n",
      "Epoch 19/200\n",
      "59968/59968 [==============================] - 4s 70us/step - loss: 0.3794\n",
      "Epoch 20/200\n",
      "59968/59968 [==============================] - 4s 71us/step - loss: 0.3858\n",
      "Epoch 21/200\n",
      "59968/59968 [==============================] - 4s 73us/step - loss: 0.4184\n",
      "        |==>  acc: 0.5503,  nmi: 0.0020  <==|\n",
      "Epoch 22/200\n",
      "59968/59968 [==============================] - 4s 69us/step - loss: 0.4001\n",
      "Epoch 23/200\n",
      "59968/59968 [==============================] - 4s 66us/step - loss: 0.3802\n",
      "Epoch 24/200\n",
      "59968/59968 [==============================] - 4s 67us/step - loss: 0.3664\n",
      "Epoch 25/200\n",
      "59968/59968 [==============================] - 4s 69us/step - loss: 0.3982\n",
      "Epoch 26/200\n",
      "59968/59968 [==============================] - 4s 69us/step - loss: 0.4441\n",
      "Epoch 27/200\n",
      "59968/59968 [==============================] - 4s 68us/step - loss: 0.3730\n",
      "Epoch 28/200\n",
      "59968/59968 [==============================] - 4s 67us/step - loss: 0.5110\n",
      "Epoch 29/200\n",
      "59968/59968 [==============================] - 4s 69us/step - loss: 0.4121\n",
      "Epoch 30/200\n",
      "59968/59968 [==============================] - 4s 68us/step - loss: 0.3916\n",
      "Epoch 31/200\n",
      "59968/59968 [==============================] - 4s 69us/step - loss: 0.4110\n",
      "Epoch 32/200\n",
      "59968/59968 [==============================] - 4s 69us/step - loss: 0.3460\n",
      "Epoch 33/200\n",
      "59968/59968 [==============================] - 4s 67us/step - loss: 0.3485\n",
      "Epoch 34/200\n",
      "59968/59968 [==============================] - 4s 67us/step - loss: 0.3850\n",
      "Epoch 35/200\n",
      "59968/59968 [==============================] - 4s 69us/step - loss: 0.3414\n",
      "Epoch 36/200\n",
      "59968/59968 [==============================] - 4s 69us/step - loss: 0.3578\n",
      "Epoch 37/200\n",
      "59968/59968 [==============================] - 4s 70us/step - loss: 0.3454\n",
      "Epoch 38/200\n",
      "59968/59968 [==============================] - 4s 70us/step - loss: 0.3700\n",
      "Epoch 39/200\n",
      "59968/59968 [==============================] - 4s 69us/step - loss: 0.3499\n",
      "Epoch 40/200\n",
      "59968/59968 [==============================] - 4s 68us/step - loss: 0.3278\n",
      "Epoch 41/200\n",
      "59968/59968 [==============================] - 4s 68us/step - loss: 0.3184\n",
      "        |==>  acc: 0.5471,  nmi: 0.0047  <==|\n",
      "Epoch 42/200\n",
      "59968/59968 [==============================] - 4s 71us/step - loss: 0.3713\n",
      "Epoch 43/200\n",
      "59968/59968 [==============================] - 4s 69us/step - loss: 0.3916\n",
      "Epoch 44/200\n",
      "59968/59968 [==============================] - 4s 68us/step - loss: 0.3394\n",
      "Epoch 45/200\n",
      "59968/59968 [==============================] - 4s 68us/step - loss: 0.3369\n",
      "Epoch 46/200\n",
      "59968/59968 [==============================] - 4s 69us/step - loss: 0.3213\n",
      "Epoch 47/200\n",
      "59968/59968 [==============================] - 4s 70us/step - loss: 0.3869\n",
      "Epoch 48/200\n",
      "59968/59968 [==============================] - 4s 72us/step - loss: 0.3213\n",
      "Epoch 49/200\n",
      "59968/59968 [==============================] - 4s 73us/step - loss: 0.3749\n",
      "Epoch 50/200\n",
      "59968/59968 [==============================] - 4s 71us/step - loss: 0.3534\n",
      "Epoch 51/200\n",
      "59968/59968 [==============================] - 4s 70us/step - loss: 0.3502\n",
      "Epoch 52/200\n",
      "59968/59968 [==============================] - 4s 70us/step - loss: 0.3242\n",
      "Epoch 53/200\n",
      "59968/59968 [==============================] - 4s 70us/step - loss: 0.3029\n",
      "Epoch 54/200\n",
      "59968/59968 [==============================] - 4s 71us/step - loss: 0.3288\n",
      "Epoch 55/200\n",
      "59968/59968 [==============================] - 4s 69us/step - loss: 0.3394\n",
      "Epoch 56/200\n",
      "59968/59968 [==============================] - 4s 71us/step - loss: 0.3758\n",
      "Epoch 57/200\n",
      "59968/59968 [==============================] - 4s 68us/step - loss: 0.3389\n",
      "Epoch 58/200\n",
      "59968/59968 [==============================] - 4s 68us/step - loss: 0.3424\n",
      "Epoch 59/200\n",
      "59968/59968 [==============================] - 4s 69us/step - loss: 0.3450\n",
      "Epoch 60/200\n",
      "59968/59968 [==============================] - 4s 68us/step - loss: 0.3117\n",
      "Epoch 61/200\n",
      "59968/59968 [==============================] - 4s 70us/step - loss: 0.3229\n",
      "        |==>  acc: 0.5495,  nmi: 0.0015  <==|\n",
      "Epoch 62/200\n",
      "59968/59968 [==============================] - 4s 73us/step - loss: 0.3610\n",
      "Epoch 63/200\n",
      "59968/59968 [==============================] - 4s 71us/step - loss: 0.3232\n",
      "Epoch 64/200\n",
      "59968/59968 [==============================] - 4s 71us/step - loss: 0.3005\n",
      "Epoch 65/200\n",
      "59968/59968 [==============================] - 4s 67us/step - loss: 0.4306\n",
      "Epoch 66/200\n",
      "59968/59968 [==============================] - 4s 67us/step - loss: 0.3964\n",
      "Epoch 67/200\n",
      "59968/59968 [==============================] - 4s 68us/step - loss: 0.3302\n",
      "Epoch 68/200\n",
      "59968/59968 [==============================] - 4s 66us/step - loss: 0.3429\n",
      "Epoch 69/200\n",
      "59968/59968 [==============================] - 4s 68us/step - loss: 0.3105\n",
      "Epoch 70/200\n",
      "59968/59968 [==============================] - 4s 66us/step - loss: 0.3121\n",
      "Epoch 71/200\n",
      "59968/59968 [==============================] - 4s 69us/step - loss: 0.3375\n",
      "Epoch 72/200\n",
      "59968/59968 [==============================] - 4s 70us/step - loss: 0.3566\n",
      "Epoch 73/200\n",
      "59968/59968 [==============================] - 4s 67us/step - loss: 0.3200\n",
      "Epoch 74/200\n",
      "59968/59968 [==============================] - 4s 71us/step - loss: 0.3101\n",
      "Epoch 75/200\n",
      "59968/59968 [==============================] - 4s 72us/step - loss: 0.3065\n",
      "Epoch 76/200\n",
      "59968/59968 [==============================] - 4s 74us/step - loss: 0.3014\n",
      "Epoch 77/200\n",
      "59968/59968 [==============================] - 4s 69us/step - loss: 0.3063\n",
      "Epoch 78/200\n",
      "59968/59968 [==============================] - 4s 70us/step - loss: 0.3163\n",
      "Epoch 79/200\n",
      "59968/59968 [==============================] - 4s 67us/step - loss: 0.2974\n",
      "Epoch 80/200\n",
      "59968/59968 [==============================] - 4s 69us/step - loss: 0.2973\n",
      "Epoch 81/200\n",
      "59968/59968 [==============================] - 4s 69us/step - loss: 0.2783\n",
      "        |==>  acc: 0.5478,  nmi: 0.0041  <==|\n",
      "Epoch 82/200\n",
      "59968/59968 [==============================] - 4s 67us/step - loss: 0.2793\n",
      "Epoch 83/200\n",
      "59968/59968 [==============================] - 4s 66us/step - loss: 0.2964\n",
      "Epoch 84/200\n",
      "59968/59968 [==============================] - 4s 66us/step - loss: 0.2824\n",
      "Epoch 85/200\n",
      "59968/59968 [==============================] - 4s 66us/step - loss: 0.3123\n",
      "Epoch 86/200\n",
      "59968/59968 [==============================] - 4s 66us/step - loss: 0.2995\n",
      "Epoch 87/200\n",
      "59968/59968 [==============================] - 4s 68us/step - loss: 0.3568\n",
      "Epoch 88/200\n",
      "59968/59968 [==============================] - 4s 69us/step - loss: 0.3086\n",
      "Epoch 89/200\n",
      "59968/59968 [==============================] - 4s 71us/step - loss: 0.3427\n",
      "Epoch 90/200\n",
      "59968/59968 [==============================] - 4s 70us/step - loss: 0.3014\n",
      "Epoch 91/200\n",
      "59968/59968 [==============================] - 4s 68us/step - loss: 0.3142\n",
      "Epoch 92/200\n",
      "59968/59968 [==============================] - 4s 66us/step - loss: 0.3290\n",
      "Epoch 93/200\n",
      "59968/59968 [==============================] - 4s 66us/step - loss: 0.3035\n",
      "Epoch 94/200\n",
      "59968/59968 [==============================] - 4s 66us/step - loss: 0.3382\n",
      "Epoch 95/200\n",
      "59968/59968 [==============================] - 4s 68us/step - loss: 0.3177\n",
      "Epoch 96/200\n",
      "59968/59968 [==============================] - 4s 69us/step - loss: 0.3145\n",
      "Epoch 97/200\n",
      "59968/59968 [==============================] - 4s 72us/step - loss: 0.2903\n",
      "Epoch 98/200\n",
      "59968/59968 [==============================] - 4s 69us/step - loss: 0.2854\n",
      "Epoch 99/200\n",
      "59968/59968 [==============================] - 4s 70us/step - loss: 0.2998\n",
      "Epoch 100/200\n",
      "59968/59968 [==============================] - 4s 70us/step - loss: 0.3153\n",
      "Epoch 101/200\n",
      "59968/59968 [==============================] - 4s 72us/step - loss: 0.2895\n",
      "        |==>  acc: 0.5464,  nmi: 0.0042  <==|\n",
      "Epoch 102/200\n",
      "59968/59968 [==============================] - 4s 68us/step - loss: 0.2980\n",
      "Epoch 103/200\n",
      "59968/59968 [==============================] - 4s 67us/step - loss: 0.2892\n",
      "Epoch 104/200\n",
      "59968/59968 [==============================] - 4s 67us/step - loss: 0.2810\n",
      "Epoch 105/200\n",
      "59968/59968 [==============================] - 4s 66us/step - loss: 0.2793\n",
      "Epoch 106/200\n",
      "59968/59968 [==============================] - 4s 66us/step - loss: 0.2753\n",
      "Epoch 107/200\n",
      "59968/59968 [==============================] - 4s 68us/step - loss: 0.2718\n",
      "Epoch 108/200\n",
      "59968/59968 [==============================] - 4s 70us/step - loss: 0.2919\n",
      "Epoch 109/200\n",
      "59968/59968 [==============================] - 4s 70us/step - loss: 0.2723\n",
      "Epoch 110/200\n",
      "59968/59968 [==============================] - 4s 71us/step - loss: 0.2714\n",
      "Epoch 111/200\n",
      "59968/59968 [==============================] - 4s 70us/step - loss: 0.2705\n",
      "Epoch 112/200\n",
      "59968/59968 [==============================] - 4s 72us/step - loss: 0.2790\n",
      "Epoch 113/200\n",
      "59968/59968 [==============================] - 4s 69us/step - loss: 0.3061\n",
      "Epoch 114/200\n",
      "59968/59968 [==============================] - 4s 70us/step - loss: 0.3340\n",
      "Epoch 115/200\n",
      "59968/59968 [==============================] - 4s 72us/step - loss: 0.2932\n",
      "Epoch 116/200\n",
      "59968/59968 [==============================] - 4s 70us/step - loss: 0.2884\n",
      "Epoch 117/200\n",
      "59968/59968 [==============================] - 4s 68us/step - loss: 0.3360\n",
      "Epoch 118/200\n",
      "59968/59968 [==============================] - 4s 69us/step - loss: 0.3023\n",
      "Epoch 119/200\n",
      "59968/59968 [==============================] - 4s 69us/step - loss: 0.2902\n",
      "Epoch 120/200\n",
      "59968/59968 [==============================] - 4s 71us/step - loss: 0.2908\n",
      "Epoch 121/200\n",
      "59968/59968 [==============================] - 4s 67us/step - loss: 0.2773\n",
      "        |==>  acc: 0.5470,  nmi: 0.0038  <==|\n",
      "Epoch 122/200\n",
      "59968/59968 [==============================] - 4s 67us/step - loss: 0.2751\n",
      "Epoch 123/200\n",
      "59968/59968 [==============================] - 4s 66us/step - loss: 0.2709\n",
      "Epoch 124/200\n",
      "59968/59968 [==============================] - 4s 66us/step - loss: 0.2756\n",
      "Epoch 125/200\n",
      "59968/59968 [==============================] - 4s 66us/step - loss: 0.2625\n",
      "Epoch 126/200\n",
      "59968/59968 [==============================] - 4s 67us/step - loss: 0.2933\n",
      "Epoch 127/200\n",
      "59968/59968 [==============================] - 4s 69us/step - loss: 0.3035\n",
      "Epoch 128/200\n",
      "59968/59968 [==============================] - 4s 69us/step - loss: 0.3185\n",
      "Epoch 129/200\n",
      "59968/59968 [==============================] - 4s 71us/step - loss: 0.2892\n",
      "Epoch 130/200\n",
      "59968/59968 [==============================] - 4s 71us/step - loss: 0.2761\n",
      "Epoch 131/200\n",
      "59968/59968 [==============================] - 4s 73us/step - loss: 0.2679\n",
      "Epoch 132/200\n",
      "59968/59968 [==============================] - 4s 71us/step - loss: 0.2652\n",
      "Epoch 133/200\n",
      "59968/59968 [==============================] - 4s 71us/step - loss: 0.3122\n",
      "Epoch 134/200\n",
      "59968/59968 [==============================] - 4s 69us/step - loss: 0.3044\n",
      "Epoch 135/200\n",
      "59968/59968 [==============================] - 4s 69us/step - loss: 0.2784\n",
      "Epoch 136/200\n",
      "59968/59968 [==============================] - 4s 68us/step - loss: 0.2727\n",
      "Epoch 137/200\n",
      "59968/59968 [==============================] - 4s 69us/step - loss: 0.2722\n",
      "Epoch 138/200\n",
      "59968/59968 [==============================] - 4s 70us/step - loss: 0.2642\n",
      "Epoch 139/200\n",
      "59968/59968 [==============================] - 4s 72us/step - loss: 0.2759\n",
      "Epoch 140/200\n",
      "59968/59968 [==============================] - 4s 70us/step - loss: 0.2723\n",
      "Epoch 141/200\n",
      "59968/59968 [==============================] - 4s 70us/step - loss: 0.2836\n",
      "        |==>  acc: 0.5464,  nmi: 0.0039  <==|\n",
      "Epoch 142/200\n",
      "59968/59968 [==============================] - 4s 73us/step - loss: 0.3021\n",
      "Epoch 143/200\n",
      "59968/59968 [==============================] - 4s 71us/step - loss: 0.2909\n",
      "Epoch 144/200\n",
      "59968/59968 [==============================] - 4s 72us/step - loss: 0.3114\n",
      "Epoch 145/200\n",
      "59968/59968 [==============================] - 4s 72us/step - loss: 0.3033\n",
      "Epoch 146/200\n",
      "59968/59968 [==============================] - 4s 66us/step - loss: 0.2768\n",
      "Epoch 147/200\n",
      "59968/59968 [==============================] - 4s 66us/step - loss: 0.2679\n",
      "Epoch 148/200\n",
      "59968/59968 [==============================] - 4s 69us/step - loss: 0.2720\n",
      "Epoch 149/200\n",
      "59968/59968 [==============================] - 4s 69us/step - loss: 0.3181\n",
      "Epoch 150/200\n",
      "59968/59968 [==============================] - 4s 71us/step - loss: 0.2725\n",
      "Epoch 151/200\n",
      "59968/59968 [==============================] - 4s 70us/step - loss: 0.2827\n",
      "Epoch 152/200\n",
      "59968/59968 [==============================] - 4s 73us/step - loss: 0.2614\n",
      "Epoch 153/200\n",
      "59968/59968 [==============================] - 4s 73us/step - loss: 0.2609\n",
      "Epoch 154/200\n",
      "59968/59968 [==============================] - 4s 71us/step - loss: 0.2579\n",
      "Epoch 155/200\n",
      "59968/59968 [==============================] - 4s 71us/step - loss: 0.2619\n",
      "Epoch 156/200\n",
      "59968/59968 [==============================] - 4s 73us/step - loss: 0.2708\n",
      "Epoch 157/200\n",
      "59968/59968 [==============================] - 4s 69us/step - loss: 0.2673\n",
      "Epoch 158/200\n",
      "59968/59968 [==============================] - 4s 69us/step - loss: 0.2683\n",
      "Epoch 159/200\n",
      "59968/59968 [==============================] - 4s 71us/step - loss: 0.2830\n",
      "Epoch 160/200\n",
      "59968/59968 [==============================] - 4s 67us/step - loss: 0.2656\n",
      "Epoch 161/200\n",
      "59968/59968 [==============================] - 4s 70us/step - loss: 0.2580\n",
      "        |==>  acc: 0.5461,  nmi: 0.0034  <==|\n",
      "Epoch 162/200\n",
      "59968/59968 [==============================] - 5s 75us/step - loss: 0.2684\n",
      "Epoch 163/200\n",
      "59968/59968 [==============================] - 4s 71us/step - loss: 0.2631\n",
      "Epoch 164/200\n",
      "59968/59968 [==============================] - 4s 72us/step - loss: 0.2531\n",
      "Epoch 165/200\n",
      "59968/59968 [==============================] - 4s 70us/step - loss: 0.2543\n",
      "Epoch 166/200\n",
      "59968/59968 [==============================] - 4s 68us/step - loss: 0.2500\n",
      "Epoch 167/200\n",
      "59968/59968 [==============================] - 4s 69us/step - loss: 0.2536\n",
      "Epoch 168/200\n",
      "59968/59968 [==============================] - 4s 71us/step - loss: 0.2670\n",
      "Epoch 169/200\n",
      "59968/59968 [==============================] - 4s 68us/step - loss: 0.2686\n",
      "Epoch 170/200\n",
      "59968/59968 [==============================] - 4s 70us/step - loss: 0.2696\n",
      "Epoch 171/200\n",
      "59968/59968 [==============================] - 4s 72us/step - loss: 0.2698\n",
      "Epoch 172/200\n",
      "59968/59968 [==============================] - 4s 72us/step - loss: 0.2704\n",
      "Epoch 173/200\n",
      "59968/59968 [==============================] - 4s 71us/step - loss: 0.2741\n",
      "Epoch 174/200\n",
      "59968/59968 [==============================] - 4s 71us/step - loss: 0.2597\n",
      "Epoch 175/200\n",
      "59968/59968 [==============================] - 4s 72us/step - loss: 0.2594\n",
      "Epoch 176/200\n",
      "59968/59968 [==============================] - 4s 71us/step - loss: 0.2636\n",
      "Epoch 177/200\n",
      "59968/59968 [==============================] - 4s 69us/step - loss: 0.2537\n",
      "Epoch 178/200\n",
      "59968/59968 [==============================] - 4s 70us/step - loss: 0.2536\n",
      "Epoch 179/200\n",
      "59968/59968 [==============================] - 4s 73us/step - loss: 0.2939\n",
      "Epoch 180/200\n",
      "59968/59968 [==============================] - 4s 73us/step - loss: 0.2718\n",
      "Epoch 181/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59968/59968 [==============================] - 4s 72us/step - loss: 0.2517\n",
      "        |==>  acc: 0.5464,  nmi: 0.0029  <==|\n",
      "Epoch 182/200\n",
      "59968/59968 [==============================] - 4s 74us/step - loss: 0.2548\n",
      "Epoch 183/200\n",
      "59968/59968 [==============================] - 4s 71us/step - loss: 0.2464\n",
      "Epoch 184/200\n",
      "59968/59968 [==============================] - 4s 73us/step - loss: 0.2496\n",
      "Epoch 185/200\n",
      "59968/59968 [==============================] - 4s 70us/step - loss: 0.2576\n",
      "Epoch 186/200\n",
      "59968/59968 [==============================] - 4s 71us/step - loss: 0.2724\n",
      "Epoch 187/200\n",
      "59968/59968 [==============================] - 4s 72us/step - loss: 0.2537\n",
      "Epoch 188/200\n",
      "59968/59968 [==============================] - 4s 71us/step - loss: 0.2550\n",
      "Epoch 189/200\n",
      "59968/59968 [==============================] - 4s 68us/step - loss: 0.2516\n",
      "Epoch 190/200\n",
      "59968/59968 [==============================] - 4s 71us/step - loss: 0.2560\n",
      "Epoch 191/200\n",
      "59968/59968 [==============================] - 4s 72us/step - loss: 0.2527\n",
      "Epoch 192/200\n",
      "59968/59968 [==============================] - 4s 75us/step - loss: 0.2510\n",
      "Epoch 193/200\n",
      "59968/59968 [==============================] - 4s 67us/step - loss: 0.2642\n",
      "Epoch 194/200\n",
      "59968/59968 [==============================] - 4s 68us/step - loss: 0.2556\n",
      "Epoch 195/200\n",
      "59968/59968 [==============================] - 4s 69us/step - loss: 0.2463\n",
      "Epoch 196/200\n",
      "59968/59968 [==============================] - 4s 72us/step - loss: 0.2563\n",
      "Epoch 197/200\n",
      "59968/59968 [==============================] - 4s 69us/step - loss: 0.2669\n",
      "Epoch 198/200\n",
      "59968/59968 [==============================] - 4s 66us/step - loss: 0.2542\n",
      "Epoch 199/200\n",
      "59968/59968 [==============================] - 4s 66us/step - loss: 0.2478\n",
      "Epoch 200/200\n",
      "59968/59968 [==============================] - 4s 68us/step - loss: 0.2518\n",
      "Pretraining time: 876s\n",
      "Pretrained weights are saved to results/temp/ae_weights.h5\n",
      "CPU times: user 13min 21s, sys: 2min 45s, total: 16min 6s\n",
      "Wall time: 14min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dec_model.pretrain(train_features, train_labels, epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update interval 140\n",
      "Save interval 9370\n",
      "Initializing cluster centers with k-means.\n",
      "Iter 0: acc = 0.54669, nmi = 0.00309, ari = -0.00539  ; loss= 0\n",
      "saving model to: ./results/temp/DEC_model_0.h5\n",
      "Iter 140: acc = 0.54834, nmi = 0.00023, ari = -0.00195  ; loss= 0.0146\n",
      "Iter 280: acc = 0.54466, nmi = 0.00006, ari = -0.00108  ; loss= 0.02081\n",
      "Iter 420: acc = 0.54192, nmi = 0.00001, ari = -0.00051  ; loss= 0.03349\n",
      "Iter 560: acc = 0.54087, nmi = 0.00001, ari = -0.00035  ; loss= 0.0234\n",
      "Iter 700: acc = 0.53602, nmi = 0.00004, ari = -0.00084  ; loss= 0.0269\n",
      "Iter 840: acc = 0.53529, nmi = 0.00002, ari = -0.00066  ; loss= 0.0177\n",
      "Iter 980: acc = 0.53487, nmi = 0.00011, ari = -0.00139  ; loss= 0.05771\n",
      "Iter 1120: acc = 0.53804, nmi = 0.00005, ari = -0.00099  ; loss= 0.04344\n",
      "Iter 1260: acc = 0.53228, nmi = 0.00020, ari = -0.00183  ; loss= 0.02283\n",
      "Iter 1400: acc = 0.53328, nmi = 0.00034, ari = -0.00238  ; loss= 0.03457\n",
      "Iter 1540: acc = 0.53167, nmi = 0.00030, ari = -0.00222  ; loss= 0.01724\n",
      "Iter 1680: acc = 0.53015, nmi = 0.00037, ari = -0.00240  ; loss= 0.06084\n",
      "Iter 1820: acc = 0.52935, nmi = 0.00022, ari = -0.00185  ; loss= 0.04118\n",
      "Iter 1960: acc = 0.52912, nmi = 0.00031, ari = -0.00216  ; loss= 0.01451\n",
      "Iter 2100: acc = 0.52968, nmi = 0.00019, ari = -0.00170  ; loss= 0.02615\n",
      "Iter 2240: acc = 0.53010, nmi = 0.00017, ari = -0.00165  ; loss= 0.02382\n",
      "Iter 2380: acc = 0.52952, nmi = 0.00015, ari = -0.00152  ; loss= 0.02052\n",
      "Iter 2520: acc = 0.53052, nmi = 0.00013, ari = -0.00142  ; loss= 0.01546\n",
      "Iter 2660: acc = 0.53057, nmi = 0.00015, ari = -0.00156  ; loss= 0.02531\n",
      "Iter 2800: acc = 0.52837, nmi = 0.00029, ari = -0.00208  ; loss= 0.02087\n",
      "Iter 2940: acc = 0.52801, nmi = 0.00030, ari = -0.00208  ; loss= 0.01983\n",
      "Iter 3080: acc = 0.52790, nmi = 0.00023, ari = -0.00182  ; loss= 0.01939\n",
      "Iter 3220: acc = 0.52526, nmi = 0.00025, ari = -0.00183  ; loss= 0.04379\n",
      "Iter 3360: acc = 0.52503, nmi = 0.00036, ari = -0.00216  ; loss= 0.07011\n",
      "Iter 3500: acc = 0.52368, nmi = 0.00039, ari = -0.00219  ; loss= 0.01121\n",
      "Iter 3640: acc = 0.52275, nmi = 0.00047, ari = -0.00237  ; loss= 0.01172\n",
      "Iter 3780: acc = 0.52271, nmi = 0.00054, ari = -0.00256  ; loss= 0.03225\n",
      "Iter 3920: acc = 0.52401, nmi = 0.00047, ari = -0.00244  ; loss= 0.01995\n",
      "Iter 4060: acc = 0.52325, nmi = 0.00052, ari = -0.00253  ; loss= 0.01314\n",
      "Iter 4200: acc = 0.52291, nmi = 0.00056, ari = -0.00260  ; loss= 0.05272\n",
      "Iter 4340: acc = 0.52068, nmi = 0.00060, ari = -0.00257  ; loss= 0.01604\n",
      "Iter 4480: acc = 0.52139, nmi = 0.00074, ari = -0.00291  ; loss= 0.01957\n",
      "Iter 4620: acc = 0.52118, nmi = 0.00071, ari = -0.00284  ; loss= 0.01559\n",
      "Iter 4760: acc = 0.52139, nmi = 0.00065, ari = -0.00272  ; loss= 0.02082\n",
      "Iter 4900: acc = 0.52149, nmi = 0.00040, ari = -0.00211  ; loss= 0.04149\n",
      "Iter 5040: acc = 0.52039, nmi = 0.00040, ari = -0.00205  ; loss= 0.01981\n",
      "Iter 5180: acc = 0.52033, nmi = 0.00022, ari = -0.00149  ; loss= 0.01405\n",
      "Iter 5320: acc = 0.52013, nmi = 0.00019, ari = -0.00138  ; loss= 0.00637\n",
      "Iter 5460: acc = 0.52023, nmi = 0.00019, ari = -0.00138  ; loss= 0.0184\n",
      "Iter 5600: acc = 0.52068, nmi = 0.00016, ari = -0.00127  ; loss= 0.01193\n",
      "Iter 5740: acc = 0.52024, nmi = 0.00016, ari = -0.00126  ; loss= 0.01529\n",
      "Iter 5880: acc = 0.52061, nmi = 0.00019, ari = -0.00140  ; loss= 0.01458\n",
      "Iter 6020: acc = 0.52123, nmi = 0.00012, ari = -0.00112  ; loss= 0.01759\n",
      "Iter 6160: acc = 0.52019, nmi = 0.00015, ari = -0.00120  ; loss= 0.01029\n",
      "Iter 6300: acc = 0.52064, nmi = 0.00011, ari = -0.00106  ; loss= 0.01694\n",
      "Iter 6440: acc = 0.52074, nmi = 0.00012, ari = -0.00108  ; loss= 0.01267\n",
      "Iter 6580: acc = 0.51949, nmi = 0.00015, ari = -0.00119  ; loss= 0.01922\n",
      "Iter 6720: acc = 0.51883, nmi = 0.00019, ari = -0.00129  ; loss= 0.01449\n",
      "Iter 6860: acc = 0.51844, nmi = 0.00015, ari = -0.00113  ; loss= 0.01112\n",
      "Iter 7000: acc = 0.51979, nmi = 0.00017, ari = -0.00128  ; loss= 0.02348\n",
      "Iter 7140: acc = 0.52053, nmi = 0.00012, ari = -0.00111  ; loss= 0.06101\n",
      "Iter 7280: acc = 0.52004, nmi = 0.00041, ari = -0.00206  ; loss= 0.11379\n",
      "Iter 7420: acc = 0.52046, nmi = 0.00036, ari = -0.00195  ; loss= 0.02192\n",
      "Iter 7560: acc = 0.52068, nmi = 0.00037, ari = -0.00199  ; loss= 0.01329\n",
      "Iter 7700: acc = 0.52408, nmi = 0.00037, ari = -0.00216  ; loss= 0.08653\n",
      "Iter 7840: acc = 0.52156, nmi = 0.00054, ari = -0.00249  ; loss= 0.00959\n",
      "Iter 7980: acc = 0.52136, nmi = 0.00054, ari = -0.00248  ; loss= 0.00976\n",
      "Iter 8120: acc = 0.52136, nmi = 0.00053, ari = -0.00245  ; loss= 0.01751\n",
      "Iter 8260: acc = 0.52101, nmi = 0.00060, ari = -0.00260  ; loss= 0.02033\n",
      "Iter 8400: acc = 0.52153, nmi = 0.00059, ari = -0.00260  ; loss= 0.09131\n",
      "Iter 8540: acc = 0.52093, nmi = 0.00064, ari = -0.00268  ; loss= 0.00795\n",
      "Iter 8680: acc = 0.52039, nmi = 0.00064, ari = -0.00265  ; loss= 0.00907\n",
      "Iter 8820: acc = 0.51833, nmi = 0.00052, ari = -0.00223  ; loss= 0.14328\n",
      "Iter 8960: acc = 0.51966, nmi = 0.00043, ari = -0.00210  ; loss= 0.00594\n",
      "Iter 9100: acc = 0.51993, nmi = 0.00034, ari = -0.00185  ; loss= 0.01258\n",
      "Iter 9240: acc = 0.51966, nmi = 0.00031, ari = -0.00174  ; loss= 0.02916\n",
      "saving model to: ./results/temp/DEC_model_9370.h5\n",
      "Iter 9380: acc = 0.51913, nmi = 0.00028, ari = -0.00164  ; loss= 0.0088\n",
      "Iter 9520: acc = 0.51913, nmi = 0.00029, ari = -0.00167  ; loss= 0.0129\n",
      "Iter 9660: acc = 0.52044, nmi = 0.00025, ari = -0.00160  ; loss= 0.01641\n",
      "Iter 9800: acc = 0.52011, nmi = 0.00024, ari = -0.00156  ; loss= 0.019\n",
      "Iter 9940: acc = 0.51883, nmi = 0.00021, ari = -0.00139  ; loss= 0.01259\n",
      "Iter 10080: acc = 0.51828, nmi = 0.00019, ari = -0.00128  ; loss= 0.01439\n",
      "Iter 10220: acc = 0.52014, nmi = 0.00020, ari = -0.00142  ; loss= 0.02675\n",
      "Iter 10360: acc = 0.51728, nmi = 0.00025, ari = -0.00143  ; loss= 0.03442\n",
      "Iter 10500: acc = 0.51674, nmi = 0.00027, ari = -0.00146  ; loss= 0.01056\n",
      "Iter 10640: acc = 0.51639, nmi = 0.00026, ari = -0.00143  ; loss= 0.00842\n",
      "Iter 10780: acc = 0.51619, nmi = 0.00026, ari = -0.00140  ; loss= 0.01479\n",
      "Iter 10920: acc = 0.51621, nmi = 0.00024, ari = -0.00136  ; loss= 0.00565\n",
      "Iter 11060: acc = 0.51516, nmi = 0.00033, ari = -0.00155  ; loss= 0.02897\n",
      "Iter 11200: acc = 0.51332, nmi = 0.00036, ari = -0.00150  ; loss= 0.00909\n",
      "Iter 11340: acc = 0.51342, nmi = 0.00036, ari = -0.00150  ; loss= 0.01568\n",
      "Iter 11480: acc = 0.51392, nmi = 0.00029, ari = -0.00138  ; loss= 0.00812\n",
      "Iter 11620: acc = 0.51307, nmi = 0.00029, ari = -0.00132  ; loss= 0.04131\n",
      "Iter 11760: acc = 0.51332, nmi = 0.00027, ari = -0.00129  ; loss= 0.00941\n",
      "Iter 11900: acc = 0.51291, nmi = 0.00022, ari = -0.00112  ; loss= 0.02344\n",
      "Iter 12040: acc = 0.51301, nmi = 0.00024, ari = -0.00117  ; loss= 0.01104\n",
      "Iter 12180: acc = 0.51279, nmi = 0.00027, ari = -0.00123  ; loss= 0.0055\n",
      "Iter 12320: acc = 0.51326, nmi = 0.00024, ari = -0.00120  ; loss= 0.00956\n",
      "Iter 12460: acc = 0.51346, nmi = 0.00022, ari = -0.00115  ; loss= 0.00858\n",
      "Iter 12600: acc = 0.51361, nmi = 0.00028, ari = -0.00132  ; loss= 0.01249\n",
      "Iter 12740: acc = 0.51316, nmi = 0.00018, ari = -0.00101  ; loss= 0.02178\n",
      "Iter 12880: acc = 0.51306, nmi = 0.00021, ari = -0.00110  ; loss= 0.01121\n",
      "Iter 13020: acc = 0.51334, nmi = 0.00021, ari = -0.00111  ; loss= 0.01363\n",
      "Iter 13160: acc = 0.51362, nmi = 0.00023, ari = -0.00119  ; loss= 0.00636\n",
      "Iter 13300: acc = 0.51376, nmi = 0.00022, ari = -0.00117  ; loss= 0.01203\n",
      "Iter 13440: acc = 0.51406, nmi = 0.00028, ari = -0.00135  ; loss= 0.03439\n",
      "Iter 13580: acc = 0.51467, nmi = 0.00024, ari = -0.00128  ; loss= 0.00933\n",
      "Iter 13720: acc = 0.51608, nmi = 0.00024, ari = -0.00134  ; loss= 0.06982\n",
      "Iter 13860: acc = 0.51491, nmi = 0.00023, ari = -0.00124  ; loss= 0.05251\n",
      "Iter 14000: acc = 0.51547, nmi = 0.00022, ari = -0.00124  ; loss= 0.00802\n",
      "Iter 14140: acc = 0.51661, nmi = 0.00026, ari = -0.00144  ; loss= 0.04422\n",
      "Iter 14280: acc = 0.51653, nmi = 0.00022, ari = -0.00129  ; loss= 0.00757\n",
      "Iter 14420: acc = 0.51649, nmi = 0.00021, ari = -0.00126  ; loss= 0.00598\n",
      "Iter 14560: acc = 0.51763, nmi = 0.00021, ari = -0.00132  ; loss= 0.02971\n",
      "Iter 14700: acc = 0.51766, nmi = 0.00020, ari = -0.00129  ; loss= 0.0057\n",
      "Iter 14840: acc = 0.51683, nmi = 0.00021, ari = -0.00127  ; loss= 0.02202\n",
      "Iter 14980: acc = 0.51651, nmi = 0.00023, ari = -0.00132  ; loss= 0.01114\n",
      "Iter 15120: acc = 0.51688, nmi = 0.00022, ari = -0.00131  ; loss= 0.00886\n",
      "Iter 15260: acc = 0.51664, nmi = 0.00024, ari = -0.00138  ; loss= 0.011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 15400: acc = 0.51793, nmi = 0.00021, ari = -0.00133  ; loss= 0.00877\n",
      "Iter 15540: acc = 0.51798, nmi = 0.00020, ari = -0.00132  ; loss= 0.00845\n",
      "Iter 15680: acc = 0.51843, nmi = 0.00022, ari = -0.00138  ; loss= 0.01279\n",
      "Iter 15820: acc = 0.51868, nmi = 0.00020, ari = -0.00135  ; loss= 0.01911\n",
      "Iter 15960: acc = 0.51906, nmi = 0.00012, ari = -0.00102  ; loss= 0.01091\n",
      "Iter 16100: acc = 0.51941, nmi = 0.00011, ari = -0.00101  ; loss= 0.01102\n",
      "Iter 16240: acc = 0.51936, nmi = 0.00011, ari = -0.00099  ; loss= 0.01057\n",
      "Iter 16380: acc = 0.51869, nmi = 0.00011, ari = -0.00099  ; loss= 0.01429\n",
      "Iter 16520: acc = 0.51854, nmi = 0.00010, ari = -0.00094  ; loss= 0.00665\n",
      "Iter 16660: acc = 0.51858, nmi = 0.00013, ari = -0.00106  ; loss= 0.02049\n",
      "Iter 16800: acc = 0.51848, nmi = 0.00010, ari = -0.00092  ; loss= 0.00925\n",
      "Iter 16940: acc = 0.51816, nmi = 0.00011, ari = -0.00097  ; loss= 0.00889\n",
      "Iter 17080: acc = 0.51963, nmi = 0.00010, ari = -0.00094  ; loss= 0.01037\n",
      "Iter 17220: acc = 0.51893, nmi = 0.00010, ari = -0.00091  ; loss= 0.00829\n",
      "Iter 17360: acc = 0.51804, nmi = 0.00016, ari = -0.00115  ; loss= 0.00881\n",
      "Iter 17500: acc = 0.51768, nmi = 0.00011, ari = -0.00096  ; loss= 0.02108\n",
      "Iter 17640: acc = 0.51768, nmi = 0.00013, ari = -0.00102  ; loss= 0.00914\n",
      "Iter 17780: acc = 0.51761, nmi = 0.00014, ari = -0.00108  ; loss= 0.00897\n",
      "Iter 17920: acc = 0.51786, nmi = 0.00012, ari = -0.00099  ; loss= 0.00598\n",
      "Iter 18060: acc = 0.51743, nmi = 0.00013, ari = -0.00102  ; loss= 0.00933\n",
      "Iter 18200: acc = 0.51793, nmi = 0.00011, ari = -0.00093  ; loss= 0.01365\n",
      "Iter 18340: acc = 0.51781, nmi = 0.00011, ari = -0.00096  ; loss= 0.02325\n",
      "Iter 18480: acc = 0.51748, nmi = 0.00014, ari = -0.00107  ; loss= 0.00623\n",
      "Iter 18620: acc = 0.51789, nmi = 0.00011, ari = -0.00095  ; loss= 0.04062\n",
      "saving model to: ./results/temp/DEC_model_18740.h5\n",
      "Iter 18760: acc = 0.51838, nmi = 0.00008, ari = -0.00081  ; loss= 0.01209\n",
      "Iter 18900: acc = 0.51813, nmi = 0.00011, ari = -0.00093  ; loss= 0.00653\n",
      "Iter 19040: acc = 0.51806, nmi = 0.00005, ari = -0.00062  ; loss= 0.2119\n",
      "Iter 19180: acc = 0.51901, nmi = 0.00003, ari = -0.00053  ; loss= 0.00887\n",
      "Iter 19320: acc = 0.51908, nmi = 0.00004, ari = -0.00056  ; loss= 0.00916\n",
      "Iter 19460: acc = 0.51914, nmi = 0.00003, ari = -0.00050  ; loss= 0.00829\n",
      "Iter 19600: acc = 0.51871, nmi = 0.00004, ari = -0.00055  ; loss= 0.00444\n",
      "Iter 19740: acc = 0.51861, nmi = 0.00004, ari = -0.00054  ; loss= 0.00705\n",
      "Iter 19880: acc = 0.51869, nmi = 0.00005, ari = -0.00065  ; loss= 0.03862\n",
      "saving model to: ./results/temp/DEC_model_final.h5\n",
      "acc: 0.518693303094984\n",
      "CPU times: user 10min 56s, sys: 2min 5s, total: 13min 2s\n",
      "Wall time: 9min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dec_model.compile(optimizer=SGD(0.01, 0.9), loss='kld')\n",
    "y_pred = dec_model.fit(train_features, y=train_labels, batch_size=32)\n",
    "print('acc:', metrics.acc(train_labels, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of the features extracted by the DEC model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clustering Output Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dec_whole_model_pred = dec_model.model.predict(train_features)\n",
    "plt.scatter(dec_whole_model_pred[:, 0], dec_whole_model_pred[:, 1], c=train_labels)\n",
    "plt.savefig(f'../data/figs/clustering_features.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoder Output Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.45 s, sys: 1.26 s, total: 7.71 s\n",
      "Wall time: 5.81 s\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "dec_encoder_model_pred = dec_model.encoder.predict(train_features)\n",
    "from sklearn.decomposition import PCA\n",
    "pca_mod = PCA(2)\n",
    "reduced_features = pca_mod.fit_transform(dec_encoder_model_pred)\n",
    "#cond_arr = (reduced_features[:, 0] < 50) & (reduced_features[:, 1] < 6)\n",
    "plt.scatter(reduced_features[:, 0], reduced_features[:, 1], c=train_labels)\n",
    "plt.savefig(f'../data/figs/encoding_pca_features.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
